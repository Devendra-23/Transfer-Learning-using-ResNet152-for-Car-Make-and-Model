{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nF-krjjnIU9I"
      },
      "id": "nF-krjjnIU9I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "sHKaj6hpIdy7"
      },
      "id": "sHKaj6hpIdy7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install console-progressbar"
      ],
      "metadata": {
        "id": "dHeyjVo9IeQV"
      },
      "id": "dHeyjVo9IeQV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai==1.0.61"
      ],
      "metadata": {
        "id": "QA8tp87EIhA-"
      },
      "id": "QA8tp87EIhA-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f696e7ee",
      "metadata": {
        "id": "f696e7ee"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "from fastai.vision.data import ImageDataBunch\n",
        "from fastai import *\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "import zipfile\n",
        "\n",
        "\n",
        "#Reference taken for the code \n",
        "# dhamvi01(2019),FastAI-Image-Classification\n",
        "# https://github.com/dhamvi01/FastAI-Image-Classification/blob/master/fastai.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1535f3ac",
      "metadata": {
        "id": "1535f3ac"
      },
      "source": [
        "# Data prprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b38b8f4",
      "metadata": {
        "id": "3b38b8f4"
      },
      "source": [
        "# Prepare data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419751d6",
      "metadata": {
        "id": "419751d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = ImageDataBunch.from_folder('/content/drive/MyDrive/cars_classification/cars_classification_dataset','train','valid',ds_tfms=get_transforms(do_flip=False, flip_vert=True, max_rotate=5.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75),size=224,bs=32).normalize(imagenet_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a719d2bf",
      "metadata": {
        "id": "a719d2bf"
      },
      "outputs": [],
      "source": [
        "# show the batches of image tha created by the model itself...\n",
        "data.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71762fd",
      "metadata": {
        "id": "d71762fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810e34e3-b180-443c-d636-8e8c2252caa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 196)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# class names and number of classes\n",
        "print(data.classes)\n",
        "len(data.classes),data.c"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fc423a",
      "metadata": {
        "id": "17fc423a"
      },
      "source": [
        "# Training: ResNet 152\n",
        "\n",
        "# For the training, using ResNet152 and batch size of 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99d844f",
      "metadata": {
        "id": "e99d844f"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "learn = cnn_learner(data, models.resnet152, metrics=accuracy)\n",
        "learn.fit(epochs)\n",
        "\n",
        "\n",
        "data = learn.recorder.plot_losses()\n",
        "data_acc = learn.recorder.plot_metrics()\n",
        "\n",
        "steps_per_epoch = int(len(data[1])/epochs)\n",
        "# print(steps_per_epoch)\n",
        "training_loss = []\n",
        "for st in range(epochs+1):\n",
        "    if st == 0:\n",
        "        training_loss.append(data[1][st])\n",
        "    else:\n",
        "        training_loss.append(data[1][(st*steps_per_epoch)-1])\n",
        "\n",
        "total_epochs = [i for i in range(epochs+1)]\n",
        "epochs_val = total_epochs.copy()\n",
        "del epochs_val[0]\n",
        "val_loss = data[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca379b6f",
      "metadata": {
        "id": "ca379b6f"
      },
      "source": [
        "# Ploting loss and accuracy graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad12a07f",
      "metadata": {
        "id": "ad12a07f"
      },
      "outputs": [],
      "source": [
        "\n",
        "figure, axis = plt.subplots(2, 2)\n",
        "# For Train Loss\n",
        "axis[0, 0].plot(total_epochs, training_loss, label='Train Loss')\n",
        "axis[0, 0].set_title(\"Train Loss\")\n",
        "# For Test Loss\n",
        "axis[0, 1].plot(epochs_val, val_loss, label='Test Loss')\n",
        "axis[0, 1].set_title(\"Test Loss\")\n",
        "# For Test Loss\n",
        "axis[1, 0].plot(epochs_val, data_acc, label='Test Accuracy')\n",
        "axis[1, 0].set_title(\"Test Accuracy\")\n",
        "# For Overall Model Evaluation\n",
        "axis[1, 1].plot(total_epochs, training_loss, label='Train Loss')\n",
        "axis[1, 1].plot(epochs_val, val_loss, label='Test Loss')\n",
        "axis[1, 1].plot(epochs_val, data_acc, label='Test Accuracy')\n",
        "axis[1, 1].set_title(\"All Training Plots\")\n",
        "axis[1, 1].legend()\n",
        "plt.savefig('resnet152_fastai_plot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ef0f0c",
      "metadata": {
        "id": "d5ef0f0c"
      },
      "outputs": [],
      "source": [
        "# calculate the accuracy\n",
        "preds,y, loss = learn.get_preds(with_loss=True)\n",
        "acc = accuracy(preds, y)\n",
        "print('The accuracy is {0} %.'.format(acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92dedfc1",
      "metadata": {
        "id": "92dedfc1"
      },
      "source": [
        "# Save and Export The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3409cb",
      "metadata": {
        "id": "1c3409cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "learn.save('/content/drive/MyDrive/cars_classification/models_resnet_152/stanford-cars-1_resnet152')\n",
        "learn.export('/content/drive/MyDrive/cars_classification/models_resnet_152/export.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}